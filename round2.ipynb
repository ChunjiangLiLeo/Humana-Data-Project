{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb835c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/7c949vv90fl9xprhlvgygqw40000gn/T/ipykernel_52273/3976071838.py:19: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  claims_data = pd.read_csv(\"mclaims.csv\")\n",
      "/var/folders/wm/7c949vv90fl9xprhlvgygqw40000gn/T/ipykernel_52273/3976071838.py:23: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  quality_data = pd.read_csv(\"QD.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# You can install these packages using pip if not installed:\n",
    "# !pip install pandas sqlite3 pandasql\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir(\"/Users/jade/Desktop/Humana/Training\")\n",
    "\n",
    "# Load datasets using pandas\n",
    "features_data = pd.read_csv(\"Afeatures.csv\")\n",
    "control_data = pd.read_csv(\"Controlpoint.csv\")\n",
    "cost_data = pd.read_csv(\"CostUt.csv\")\n",
    "demograph_data = pd.read_csv(\"Demographics.csv\")\n",
    "condition_data = pd.read_csv(\"mcondition.csv\")\n",
    "detail_data = pd.read_csv(\"mdetail.csv\")\n",
    "claims_data = pd.read_csv(\"mclaims.csv\")\n",
    "target_data = pd.read_csv(\"Tmembers.csv\")\n",
    "members_data = pd.read_csv(\"mdata.csv\")\n",
    "pharmacy_data = pd.read_csv(\"PU.csv\")\n",
    "quality_data = pd.read_csv(\"QD.csv\")\n",
    "sales_data = pd.read_csv(\"SC.csv\")\n",
    "social_data = pd.read_csv(\"Socialh.csv\")\n",
    "web_data = pd.read_csv(\"WA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7824956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_tenure(value):\n",
    "    # Check if value is a string before processing\n",
    "    if isinstance(value, str):\n",
    "        # If the format is 'X - Y YEARS', calculate the midpoint\n",
    "        if '-' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 2:  # Ensure there are two numbers for the range\n",
    "                return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "        # If the format is 'X+ YEARS', take the number before the '+'\n",
    "        elif '+' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:  # Ensure there's at least one number\n",
    "                return float(numbers[0])\n",
    "        # If there's just 'X YEARS', return the number\n",
    "        elif 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:\n",
    "                return float(numbers[0])\n",
    "        # Default case for strings that don't match the expected format\n",
    "        return None\n",
    "    # If value is already a float or an int, return it as is\n",
    "    elif isinstance(value, (float, int)):\n",
    "        return value\n",
    "    # Default return for unexpected types (e.g., NaN, None)\n",
    "    return None\n",
    "\n",
    "# Applying the function to the column\n",
    "members_data['tenure_band'] = members_data['tenure_band'].apply(convert_tenure)\n",
    "members_data['disabled_ind'] = members_data['disabled_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_data['dual_eligible_ind'] = members_data['dual_eligible_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_data['lis_ind']= members_data['lis_ind'].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5892656",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(members_data, pharmacy_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, social_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, web_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861dce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target=target_data.drop(['product_type','calendar_year','plan_category'],axis=1)\n",
    "merged_data = pd.merge(merged_data, new_target, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, features_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, control_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, cost_data, on='id', how='inner')\n",
    "demograph_data=demograph_data.drop(columns=['lang_spoken_cd', 'rucc_category'])\n",
    "merged_data = pd.merge(merged_data, demograph_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb0751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 231 entries, consec_tenure_month to channel\n",
      "dtypes: float64(224), int64(7)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "sales_data['channel'] = sales_data['channel'].map({\n",
    "    'Field':0,\n",
    "    'Consumer Direct': 1,\n",
    "    'Partner Call Center': 2,\n",
    "    'DMS Telesales': 3,\n",
    "    'Brokerage': 4\n",
    "})\n",
    "merged_data = pd.merge(merged_data, sales_data, on='id', how='inner')\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35c218b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Mapping: {'Florida': 0, 'Gulf South': 1, 'South Central': 2, 'Southeast': 3, 'Midwest': 4, 'Northeast': 5, 'Intermountain': 6, 'Central': 7, 'Pacific Southwest': 8, 'Puerto Rico': 9, 'Unknown': 10}\n",
      "Race Mapping: {'Unknown': 0, 'BLACK': 1, 'N AMERICAN NATIVE': 2, 'WHITE': 3, 'ASIAN': 4, 'HISPANIC': 5, 'UNKNOWN': 6, 'OTHER': 7}\n"
     ]
    }
   ],
   "source": [
    "region_mapping = {region: idx for idx, region in enumerate(detail_data['region'].fillna('Unknown').unique())}\n",
    "race_mapping = {race: idx for idx, race in enumerate(detail_data['race'].fillna('Unknown').unique())}\n",
    "\n",
    "# Print the mappings to see what was assigned (optional)\n",
    "print(\"Region Mapping:\", region_mapping)\n",
    "print(\"Race Mapping:\", race_mapping)\n",
    "\n",
    "# Map the 'region' column to numeric values and overwrite the original column\n",
    "detail_data['region'] = detail_data['region'].fillna('Unknown').map(region_mapping)\n",
    "\n",
    "# Map the 'race' column to numeric values and overwrite the original column\n",
    "detail_data['race'] = detail_data['race'].fillna('Unknown').map(race_mapping)\n",
    "detail_data=detail_data.drop(columns=['mco_contract_nbr','state_of_residence','county_of_residence'])\n",
    "detail_data['generic_grouper'] = detail_data['generic_grouper'].fillna(10008)\n",
    "detail_data['generic_grouper'] = detail_data['generic_grouper'].replace({'Y': 1, 'N': 0})\n",
    "detail_data['unattributed_provider'] = detail_data['unattributed_provider'].fillna(10008)\n",
    "detail_data['unattributed_provider'] = detail_data['unattributed_provider'].replace({'Y': 1, 'N': 0})\n",
    "detail_data['sex_cd'] = detail_data['sex_cd'].fillna(10008)\n",
    "detail_data['sex_cd'] = detail_data['sex_cd'].replace({'F': 1, 'M': 0,'U':10008})\n",
    "detail_data['veteran_ind'] = detail_data['veteran_ind'].fillna(10008)\n",
    "detail_data['veteran_ind'] = detail_data['veteran_ind'].replace({'Y': 1, 'N': 0})\n",
    "merged_data = pd.merge(merged_data, detail_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8bd406",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_aggregated = condition_data.groupby('id').agg({\n",
    "    'hcc_model_type': lambda x: ', '.join(x),  # Join diseases as a single string\n",
    "}).reset_index()\n",
    "condition_aggregated\n",
    "def remove_duplicates(hcc_model_type):\n",
    "    # Split the string into a list, remove duplicates using set, and join it back into a string\n",
    "    unique_terms = ', '.join(sorted(set(hcc_model_type.split(', '))))\n",
    "    return unique_terms\n",
    "\n",
    "# Apply the function to remove duplicates from 'cond_desc' column\n",
    "condition_aggregated['hcc_model_type'] = condition_aggregated['hcc_model_type'].apply(remove_duplicates)\n",
    "merged_data = pd.merge(merged_data, condition_aggregated, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee2f247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 241 entries, consec_tenure_month to hcc_model_type\n",
      "dtypes: float64(224), int64(17)\n",
      "memory usage: 2.7 GB\n"
     ]
    }
   ],
   "source": [
    "merged_data['hcc_model_type'] = merged_data['hcc_model_type'].fillna(0)\n",
    "\n",
    "# Step 2: Replace specific strings with numeric values\n",
    "merged_data['hcc_model_type'] = merged_data['hcc_model_type'].replace({'U': 0, 'MEDICAL': 1, 'ESRD': 2})\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71350112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace 'Y' with 1 and everything else (including NaN) with 0\n",
    "claims_data_numeric = claims_data.replace({'Y': 1}).fillna(0)\n",
    "\n",
    "# Step 2: Group by 'id' and sum the numeric values to count the number of 'Y's in each column\n",
    "claims_data_group = claims_data_numeric.groupby('id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18a0cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_data_group=claims_data_group.drop(columns = ['dos_year','clm_unique_key','serv_date_skey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88101251",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, claims_data_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d92b888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 264 entries, consec_tenure_month to er_visit\n",
      "dtypes: float64(247), int64(17)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0226a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_data = quality_data.drop(columns = ['measurement_year','measure_name','measure_desc','base_event_date','eligible_cnt'])\n",
    "quality_data['measure_type'] = quality_data['measure_type'].fillna(10008)\n",
    "quality_data['measure_type'] = quality_data['measure_type'].replace({'Patient Safety': 1, 'Patient Experience': 0, 'HEDIS':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e95cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_data_group=quality_data.groupby('id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "416090f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, quality_data_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae99472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "X = merged_data.drop(columns=['preventive_visit_gap_ind'])  # Features\n",
    "y = merged_data['preventive_visit_gap_ind']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'learning_rate': Real(0.01, 1.0, prior='log-uniform'),\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'n_estimators': Integer(50, 300),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "    'colsample_bytree': Real(0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Setup the Bayesian Optimization with cross-validation\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=32,  # Number of parameter settings that are sampled\n",
    "    cv=3,       # 3-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the Bayesian Optimization model\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters found by Bayesian Optimization:\")\n",
    "print(bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Setup the Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,        # 3-fold cross-validation\n",
    "    n_jobs=-1,   # Use all available cores\n",
    "    verbose=1    # Show progress\n",
    ")\n",
    "\n",
    "# Fit the Grid Search model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(\"Best parameters found by Grid Search:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f45eb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
