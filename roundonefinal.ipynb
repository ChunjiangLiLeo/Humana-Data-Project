{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd2a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/7c949vv90fl9xprhlvgygqw40000gn/T/ipykernel_7039/3976071838.py:19: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  claims_data = pd.read_csv(\"mclaims.csv\")\n",
      "/var/folders/wm/7c949vv90fl9xprhlvgygqw40000gn/T/ipykernel_7039/3976071838.py:23: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  quality_data = pd.read_csv(\"QD.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# You can install these packages using pip if not installed:\n",
    "# !pip install pandas sqlite3 pandasql\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir(\"/Users/jade/Desktop/Humana/Training\")\n",
    "\n",
    "# Load datasets using pandas\n",
    "features_data = pd.read_csv(\"Afeatures.csv\")\n",
    "control_data = pd.read_csv(\"Controlpoint.csv\")\n",
    "cost_data = pd.read_csv(\"CostUt.csv\")\n",
    "demograph_data = pd.read_csv(\"Demographics.csv\")\n",
    "condition_data = pd.read_csv(\"mcondition.csv\")\n",
    "detail_data = pd.read_csv(\"mdetail.csv\")\n",
    "claims_data = pd.read_csv(\"mclaims.csv\")\n",
    "target_data = pd.read_csv(\"Tmembers.csv\")\n",
    "members_data = pd.read_csv(\"mdata.csv\")\n",
    "pharmacy_data = pd.read_csv(\"PU.csv\")\n",
    "quality_data = pd.read_csv(\"QD.csv\")\n",
    "sales_data = pd.read_csv(\"SC.csv\")\n",
    "social_data = pd.read_csv(\"Socialh.csv\")\n",
    "web_data = pd.read_csv(\"WA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8040738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_tenure(value):\n",
    "    # Check if value is a string before processing\n",
    "    if isinstance(value, str):\n",
    "        # If the format is 'X - Y YEARS', calculate the midpoint\n",
    "        if '-' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 2:  # Ensure there are two numbers for the range\n",
    "                return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "        # If the format is 'X+ YEARS', take the number before the '+'\n",
    "        elif '+' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:  # Ensure there's at least one number\n",
    "                return float(numbers[0])\n",
    "        # If there's just 'X YEARS', return the number\n",
    "        elif 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:\n",
    "                return float(numbers[0])\n",
    "        # Default case for strings that don't match the expected format\n",
    "        return None\n",
    "    # If value is already a float or an int, return it as is\n",
    "    elif isinstance(value, (float, int)):\n",
    "        return value\n",
    "    # Default return for unexpected types (e.g., NaN, None)\n",
    "    return None\n",
    "\n",
    "# Applying the function to the column\n",
    "members_data['tenure_band'] = members_data['tenure_band'].apply(convert_tenure)\n",
    "members_data['disabled_ind'] = members_data['disabled_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_data['dual_eligible_ind'] = members_data['dual_eligible_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_data['lis_ind']= members_data['lis_ind'].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e95918",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(members_data, pharmacy_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, social_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, web_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a564e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target=target_data.drop(['product_type','calendar_year','plan_category'],axis=1)\n",
    "merged_data = pd.merge(merged_data, new_target, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, features_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, control_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, cost_data, on='id', how='inner')\n",
    "demograph_data=demograph_data.drop(columns=['lang_spoken_cd', 'rucc_category'])\n",
    "merged_data = pd.merge(merged_data, demograph_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d40639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 231 entries, consec_tenure_month to channel\n",
      "dtypes: float64(224), int64(7)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "sales_data['channel'] = sales_data['channel'].map({\n",
    "    'Field':0,\n",
    "    'Consumer Direct': 1,\n",
    "    'Partner Call Center': 2,\n",
    "    'DMS Telesales': 3,\n",
    "    'Brokerage': 4\n",
    "})\n",
    "merged_data = pd.merge(merged_data, sales_data, on='id', how='inner')\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5692609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Mapping: {'Florida': 0, 'Gulf South': 1, 'South Central': 2, 'Southeast': 3, 'Midwest': 4, 'Northeast': 5, 'Intermountain': 6, 'Central': 7, 'Pacific Southwest': 8, 'Puerto Rico': 9, 'Unknown': 10}\n",
      "Race Mapping: {'Unknown': 0, 'BLACK': 1, 'N AMERICAN NATIVE': 2, 'WHITE': 3, 'ASIAN': 4, 'HISPANIC': 5, 'UNKNOWN': 6, 'OTHER': 7}\n"
     ]
    }
   ],
   "source": [
    "region_mapping = {region: idx for idx, region in enumerate(detail_data['region'].fillna('Unknown').unique())}\n",
    "race_mapping = {race: idx for idx, race in enumerate(detail_data['race'].fillna('Unknown').unique())}\n",
    "\n",
    "# Print the mappings to see what was assigned (optional)\n",
    "print(\"Region Mapping:\", region_mapping)\n",
    "print(\"Race Mapping:\", race_mapping)\n",
    "\n",
    "# Map the 'region' column to numeric values and overwrite the original column\n",
    "detail_data['region'] = detail_data['region'].fillna('Unknown').map(region_mapping)\n",
    "\n",
    "# Map the 'race' column to numeric values and overwrite the original column\n",
    "detail_data['race'] = detail_data['race'].fillna('Unknown').map(race_mapping)\n",
    "detail_data=detail_data.drop(columns=['mco_contract_nbr','state_of_residence','county_of_residence'])\n",
    "detail_data['generic_grouper'] = detail_data['generic_grouper'].fillna(10008)\n",
    "detail_data['generic_grouper'] = detail_data['generic_grouper'].replace({'Y': 1, 'N': 0})\n",
    "detail_data['unattributed_provider'] = detail_data['unattributed_provider'].fillna(10008)\n",
    "detail_data['unattributed_provider'] = detail_data['unattributed_provider'].replace({'Y': 1, 'N': 0})\n",
    "detail_data['sex_cd'] = detail_data['sex_cd'].fillna(10008)\n",
    "detail_data['sex_cd'] = detail_data['sex_cd'].replace({'F': 1, 'M': 0,'U':10008})\n",
    "detail_data['veteran_ind'] = detail_data['veteran_ind'].fillna(10008)\n",
    "detail_data['veteran_ind'] = detail_data['veteran_ind'].replace({'Y': 1, 'N': 0})\n",
    "merged_data = pd.merge(merged_data, detail_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f19efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_aggregated = condition_data.groupby('id').agg({\n",
    "    'hcc_model_type': lambda x: ', '.join(x),  # Join diseases as a single string\n",
    "}).reset_index()\n",
    "condition_aggregated\n",
    "def remove_duplicates(hcc_model_type):\n",
    "    # Split the string into a list, remove duplicates using set, and join it back into a string\n",
    "    unique_terms = ', '.join(sorted(set(hcc_model_type.split(', '))))\n",
    "    return unique_terms\n",
    "\n",
    "# Apply the function to remove duplicates from 'cond_desc' column\n",
    "condition_aggregated['hcc_model_type'] = condition_aggregated['hcc_model_type'].apply(remove_duplicates)\n",
    "merged_data = pd.merge(merged_data, condition_aggregated, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['hcc_model_type'] = merged_data['hcc_model_type'].fillna(0)\n",
    "\n",
    "# Step 2: Replace specific strings with numeric values\n",
    "merged_data['hcc_model_type'] = merged_data['hcc_model_type'].replace({'U': 0, 'MEDICAL': 1, 'ESRD': 2})\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b958e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace 'Y' with 1 and everything else (including NaN) with 0\n",
    "claims_data_numeric = claims_data.replace({'Y': 1}).fillna(0)\n",
    "\n",
    "# Step 2: Group by 'id' and sum the numeric values to count the number of 'Y's in each column\n",
    "claims_data_group = claims_data_numeric.groupby('id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c9e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_data_group=claims_data_group.drop(columns = ['dos_year','clm_unique_key','serv_date_skey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3a91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, claims_data_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e21f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_data = quality_data.drop(columns = ['measurement_year','measure_name','measure_desc','base_event_date','eligible_cnt'])\n",
    "quality_data['measure_type'] = quality_data['measure_type'].fillna(10008)\n",
    "quality_data['measure_type'] = quality_data['measure_type'].replace({'Patient Safety': 1, 'Patient Experience': 0, 'HEDIS':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ac01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_data_group=quality_data.groupby('id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc4432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, quality_data_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254971f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ff5b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jade/Desktop/Humana/Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# You can install these packages using pip if not installed:\n",
    "# !pip install pandas sqlite3 pandasql\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir(\"/Users/jade/Desktop/Humana/Holdout_final\")\n",
    "# Load datasets using pandas\n",
    "features_test = pd.read_csv(\"AFH.csv\")\n",
    "control_test = pd.read_csv(\"ControlH.csv\")\n",
    "cost_test = pd.read_csv(\"CostH.csv\")\n",
    "demograph_test = pd.read_csv(\"DemographH.csv\")\n",
    "condition_test = pd.read_csv(\"ConditionH.csv\")\n",
    "detail_test = pd.read_csv(\"DetailH.csv\")\n",
    "claims_test = pd.read_csv(\"ClaimsH.csv\")\n",
    "target_test = pd.read_csv(\"TargetH.csv\")\n",
    "members_test = pd.read_csv(\"MemberH.csv\")\n",
    "pharmacy_test= pd.read_csv(\"PharmacyH.csv\")\n",
    "quality_test = pd.read_csv(\"QualityH.csv\")\n",
    "sales_test = pd.read_csv(\"SalesH.csv\")\n",
    "social_test = pd.read_csv(\"SocialH.csv\")\n",
    "web_test = pd.read_csv(\"WebH.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce637f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_tenure(value):\n",
    "    # Check if value is a string before processing\n",
    "    if isinstance(value, str):\n",
    "        # If the format is 'X - Y YEARS', calculate the midpoint\n",
    "        if '-' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 2:  # Ensure there are two numbers for the range\n",
    "                return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "        # If the format is 'X+ YEARS', take the number before the '+'\n",
    "        elif '+' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:  # Ensure there's at least one number\n",
    "                return float(numbers[0])\n",
    "        # If there's just 'X YEARS', return the number\n",
    "        elif 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:\n",
    "                return float(numbers[0])\n",
    "        # Default case for strings that don't match the expected format\n",
    "        return None\n",
    "    # If value is already a float or an int, return it as is\n",
    "    elif isinstance(value, (float, int)):\n",
    "        return value\n",
    "    # Default return for unexpected types (e.g., NaN, None)\n",
    "    return None\n",
    "\n",
    "# Applying the function to the column\n",
    "members_test['tenure_band'] = members_test['tenure_band'].apply(convert_tenure)\n",
    "members_test['disabled_ind'] = members_test['disabled_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_test['dual_eligible_ind'] = members_test['dual_eligible_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_test['lis_ind']= members_test['lis_ind'].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "271bef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test = pd.merge(members_test, pharmacy_test, on='id', how='inner')\n",
    "merged_test = pd.merge(merged_test, social_test, on='id', how='inner')\n",
    "merged_test = pd.merge(merged_test, web_test, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af7434ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target_test=target_test.drop(['product_type','calendar_year','plan_category'],axis=1)\n",
    "merged_test = pd.merge(merged_test, new_target_test, on='id', how='inner')\n",
    "merged_test = pd.merge(merged_test, features_test, on='id', how='inner')\n",
    "merged_test = pd.merge(merged_test, control_test, on='id', how='inner')\n",
    "merged_test = pd.merge(merged_test, cost_test, on='id', how='inner')\n",
    "demograph_test=demograph_test.drop(columns=['lang_spoken_cd', 'rucc_category'])\n",
    "merged_test = pd.merge(merged_test, demograph_test, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716724d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test['channel'] = sales_test['channel'].map({\n",
    "    'Field':0,\n",
    "    'Consumer Direct': 1,\n",
    "    'Partner Call Center': 2,\n",
    "    'DMS Telesales': 3,\n",
    "    'Brokerage': 4\n",
    "})\n",
    "merged_test = pd.merge(merged_test, sales_test, on='id', how='inner')\n",
    "merged_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_mapping = {region: idx for idx, region in enumerate(detail_test['region'].fillna('Unknown').unique())}\n",
    "race_mapping = {race: idx for idx, race in enumerate(detail_test['race'].fillna('Unknown').unique())}\n",
    "\n",
    "# Print the mappings to see what was assigned (optional)\n",
    "print(\"Region Mapping:\", region_mapping)\n",
    "print(\"Race Mapping:\", race_mapping)\n",
    "\n",
    "# Map the 'region' column to numeric values and overwrite the original column\n",
    "detail_test['region'] = detail_test['region'].fillna('Unknown').map(region_mapping)\n",
    "\n",
    "# Map the 'race' column to numeric values and overwrite the original column\n",
    "detail_test['race'] = detail_test['race'].fillna('Unknown').map(race_mapping)\n",
    "detail_test=detail_test.drop(columns=['mco_contract_nbr','state_of_residence','county_of_residence'])\n",
    "detail_test['generic_grouper'] = detail_test['generic_grouper'].fillna(10008)\n",
    "detail_test['generic_grouper'] = detail_test['generic_grouper'].replace({'Y': 1, 'N': 0})\n",
    "detail_test['unattributed_provider'] = detail_test['unattributed_provider'].fillna(10008)\n",
    "detail_test['unattributed_provider'] = detail_test['unattributed_provider'].replace({'Y': 1, 'N': 0})\n",
    "detail_test['sex_cd'] = detail_test['sex_cd'].fillna(10008)\n",
    "detail_test['sex_cd'] = detail_test['sex_cd'].replace({'F': 1, 'M': 0,'U':10008})\n",
    "detail_test['veteran_ind'] = detail_test['veteran_ind'].fillna(10008)\n",
    "detail_test['veteran_ind'] = detail_test['veteran_ind'].replace({'Y': 1, 'N': 0})\n",
    "merged_test = pd.merge(merged_test, detail_test, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bd5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da7ae665",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_test = condition_test.groupby('id').agg({\n",
    "    'hcc_model_type': lambda x: ', '.join(x),  # Join diseases as a single string\n",
    "}).reset_index()\n",
    "condition_test\n",
    "def remove_duplicates(hcc_model_type):\n",
    "    # Split the string into a list, remove duplicates using set, and join it back into a string\n",
    "    unique_terms = ', '.join(sorted(set(hcc_model_type.split(', '))))\n",
    "    return unique_terms\n",
    "\n",
    "# Apply the function to remove duplicates from 'cond_desc' column\n",
    "condition_test['hcc_model_type'] = condition_test['hcc_model_type'].apply(remove_duplicates)\n",
    "merged_test = pd.merge(merged_test, condition_test, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test['hcc_model_type'] = merged_test['hcc_model_type'].fillna(0)\n",
    "\n",
    "# Step 2: Replace specific strings with numeric values\n",
    "merged_test['hcc_model_type'] = merged_test['hcc_model_type'].replace({'U': 0, 'MEDICAL': 1, 'ESRD': 2})\n",
    "merged_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82bdc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace 'Y' with 1 and everything else (including NaN) with 0\n",
    "claims_test_numeric = claims_test.replace({'Y': 1}).fillna(0)\n",
    "\n",
    "# Step 2: Group by 'id' and sum the numeric values to count the number of 'Y's in each column\n",
    "claims_test_group = claims_test_numeric.groupby('id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e694a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_test_group=claims_test_group.drop(columns = ['dos_year','clm_unique_key','serv_date_skey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e800b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test = pd.merge(merged_test, claims_test_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b95310",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_test = quality_test.drop(columns = ['measurement_year','measure_name','measure_desc','base_event_date','eligible_cnt'])\n",
    "quality_test['measure_type'] = quality_test['measure_type'].fillna(10008)\n",
    "quality_test['measure_type'] = quality_test['measure_type'].replace({'Patient Safety': 1, 'Patient Experience': 0, 'HEDIS':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f10cf8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_test_group=quality_test.groupby('id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bb6766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_test = pd.merge(merged_test, quality_test_group, on='id', how='outer')\n",
    "merged_testn=pd.merge(merged_test, quality_test_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f57478",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_testn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'merged_data' and 'merged_testn' are pandas DataFrames\n",
    "\n",
    "# Separate features and target variable from training data\n",
    "X_train = merged_data.drop(columns=['preventive_visit_gap_ind','id'])  # Drop 'id' from the training features\n",
    "y_train = merged_data['preventive_visit_gap_ind']\n",
    "\n",
    "# Extract features from test data (ensure 'id' is dropped for features, but kept for final output)\n",
    "X_test = merged_testn.drop(columns=['id'])  # Drop 'id' from the test features\n",
    "test_ids = merged_testn['id']  # Keep 'id' for the final CSV output\n",
    "\n",
    "# Optional: Scaling (depends on your dataset)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the data, and keep it as a DataFrame with the same column names\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost model (XGBClassifier for classification or XGBRegressor for regression)\n",
    "xgb_model = xgb.XGBClassifier()  # Replace with XGBRegressor() for regression tasks\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the scores for test data\n",
    "test_scores = xgb_model.predict_proba(X_test_scaled)[:, 1]  # For classification, use the probability of the positive class\n",
    "\n",
    "# Create a DataFrame with original 'id', 'score', and rank based on highest score first\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': test_ids,      # Use original patient IDs\n",
    "    'SCORE': test_scores # Predicted scores\n",
    "})\n",
    "\n",
    "# Rank the predictions (highest scores should have rank 1)\n",
    "output_df['RANK'] = output_df['SCORE'].rank(ascending=False, method='first')\n",
    "\n",
    "# Sort the DataFrame by 'score' in descending order\n",
    "output_df_sorted = output_df.sort_values(by='SCORE', ascending=False)\n",
    "\n",
    "# Optionally reset the index if you want a clean sequential index\n",
    "output_df_sorted = output_df_sorted.reset_index(drop=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(output_df_sorted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05370461",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = xgb_model.get_booster().get_score(importance_type='weight') \n",
    "sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "top_10_features = sorted_importance[:10]\n",
    "\n",
    "# Print the top 10 features with their importance scores\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd66971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Assuming X_train and y_train are your training data\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use TreeExplainer for XGBoost models\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Get SHAP values for the training data\n",
    "shap_values = explainer.shap_values(X_train_scaled)\n",
    "\n",
    "# Plot summary of SHAP values\n",
    "shap.summary_plot(shap_values, X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10471074",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[0], X_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155acbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
