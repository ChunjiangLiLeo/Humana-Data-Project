{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd2a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/7c949vv90fl9xprhlvgygqw40000gn/T/ipykernel_5732/3976071838.py:19: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  claims_data = pd.read_csv(\"mclaims.csv\")\n",
      "/var/folders/wm/7c949vv90fl9xprhlvgygqw40000gn/T/ipykernel_5732/3976071838.py:23: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  quality_data = pd.read_csv(\"QD.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# You can install these packages using pip if not installed:\n",
    "# !pip install pandas sqlite3 pandasql\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir(\"/Users/jade/Desktop/Humana/Training\")\n",
    "\n",
    "# Load datasets using pandas\n",
    "features_data = pd.read_csv(\"Afeatures.csv\")\n",
    "control_data = pd.read_csv(\"Controlpoint.csv\")\n",
    "cost_data = pd.read_csv(\"CostUt.csv\")\n",
    "demograph_data = pd.read_csv(\"Demographics.csv\")\n",
    "condition_data = pd.read_csv(\"mcondition.csv\")\n",
    "detail_data = pd.read_csv(\"mdetail.csv\")\n",
    "claims_data = pd.read_csv(\"mclaims.csv\")\n",
    "target_data = pd.read_csv(\"Tmembers.csv\")\n",
    "members_data = pd.read_csv(\"mdata.csv\")\n",
    "pharmacy_data = pd.read_csv(\"PU.csv\")\n",
    "quality_data = pd.read_csv(\"QD.csv\")\n",
    "sales_data = pd.read_csv(\"SC.csv\")\n",
    "social_data = pd.read_csv(\"Socialh.csv\")\n",
    "web_data = pd.read_csv(\"WA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8040738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_tenure(value):\n",
    "    # Check if value is a string before processing\n",
    "    if isinstance(value, str):\n",
    "        # If the format is 'X - Y YEARS', calculate the midpoint\n",
    "        if '-' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 2:  # Ensure there are two numbers for the range\n",
    "                return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "        # If the format is 'X+ YEARS', take the number before the '+'\n",
    "        elif '+' in value and 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:  # Ensure there's at least one number\n",
    "                return float(numbers[0])\n",
    "        # If there's just 'X YEARS', return the number\n",
    "        elif 'YEARS' in value:\n",
    "            numbers = re.findall(r'\\d*\\.?\\d+', value)\n",
    "            if len(numbers) == 1:\n",
    "                return float(numbers[0])\n",
    "        # Default case for strings that don't match the expected format\n",
    "        return None\n",
    "    # If value is already a float or an int, return it as is\n",
    "    elif isinstance(value, (float, int)):\n",
    "        return value\n",
    "    # Default return for unexpected types (e.g., NaN, None)\n",
    "    return None\n",
    "\n",
    "# Applying the function to the column\n",
    "members_data['tenure_band'] = members_data['tenure_band'].apply(convert_tenure)\n",
    "members_data['disabled_ind'] = members_data['disabled_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_data['dual_eligible_ind'] = members_data['dual_eligible_ind'].replace({'Y': 1, 'N': 0})\n",
    "members_data['lis_ind']= members_data['lis_ind'].replace({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e95918",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(members_data, pharmacy_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, social_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, web_data, on='id', how='inner')\n",
    "demograph_data = pd.read_csv(\"Demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a564e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target=target_data.drop(['product_type','calendar_year','plan_category'],axis=1)\n",
    "merged_data = pd.merge(merged_data, new_target, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, features_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, control_data, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, cost_data, on='id', how='inner')\n",
    "demograph_data=demograph_data.drop(columns=['lang_spoken_cd', 'rucc_category'])\n",
    "merged_data = pd.merge(merged_data, demograph_data, on='id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d40639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 231 entries, consec_tenure_month to channel\n",
      "dtypes: float64(224), int64(7)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "sales_data['channel'] = sales_data['channel'].map({\n",
    "    'Field':0,\n",
    "    'Consumer Direct': 1,\n",
    "    'Partner Call Center': 2,\n",
    "    'DMS Telesales': 3,\n",
    "    'Brokerage': 4\n",
    "})\n",
    "merged_data = pd.merge(merged_data, sales_data, on='id', how='inner')\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5692609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region Mapping: {'Florida': 0, 'Gulf South': 1, 'South Central': 2, 'Southeast': 3, 'Midwest': 4, 'Northeast': 5, 'Intermountain': 6, 'Central': 7, 'Pacific Southwest': 8, 'Puerto Rico': 9, 'Unknown': 10}\n",
      "Race Mapping: {'Unknown': 0, 'BLACK': 1, 'N AMERICAN NATIVE': 2, 'WHITE': 3, 'ASIAN': 4, 'HISPANIC': 5, 'UNKNOWN': 6, 'OTHER': 7}\n"
     ]
    }
   ],
   "source": [
    "region_mapping = {region: idx for idx, region in enumerate(detail_data['region'].fillna('Unknown').unique())}\n",
    "race_mapping = {race: idx for idx, race in enumerate(detail_data['race'].fillna('Unknown').unique())}\n",
    "\n",
    "# Print the mappings to see what was assigned (optional)\n",
    "print(\"Region Mapping:\", region_mapping)\n",
    "print(\"Race Mapping:\", race_mapping)\n",
    "\n",
    "# Map the 'region' column to numeric values and overwrite the original column\n",
    "detail_data['region'] = detail_data['region'].fillna('Unknown').map(region_mapping)\n",
    "\n",
    "# Map the 'race' column to numeric values and overwrite the original column\n",
    "detail_data['race'] = detail_data['race'].fillna('Unknown').map(race_mapping)\n",
    "detail_data=detail_data.drop(columns=['mco_contract_nbr','state_of_residence','county_of_residence'])\n",
    "detail_data['generic_grouper'] = detail_data['generic_grouper'].fillna(10008)\n",
    "detail_data['generic_grouper'] = detail_data['generic_grouper'].replace({'Y': 1, 'N': 0})\n",
    "detail_data['unattributed_provider'] = detail_data['unattributed_provider'].fillna(10008)\n",
    "detail_data['unattributed_provider'] = detail_data['unattributed_provider'].replace({'Y': 1, 'N': 0})\n",
    "detail_data['sex_cd'] = detail_data['sex_cd'].fillna(10008)\n",
    "detail_data['sex_cd'] = detail_data['sex_cd'].replace({'F': 1, 'M': 0,'U':10008})\n",
    "detail_data['veteran_ind'] = detail_data['veteran_ind'].fillna(10008)\n",
    "detail_data['veteran_ind'] = detail_data['veteran_ind'].replace({'Y': 1, 'N': 0})\n",
    "merged_data = pd.merge(merged_data, detail_data, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f19efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_aggregated = condition_data.groupby('id').agg({\n",
    "    'hcc_model_type': lambda x: ', '.join(x),  # Join diseases as a single string\n",
    "}).reset_index()\n",
    "condition_aggregated\n",
    "def remove_duplicates(hcc_model_type):\n",
    "    # Split the string into a list, remove duplicates using set, and join it back into a string\n",
    "    unique_terms = ', '.join(sorted(set(hcc_model_type.split(', '))))\n",
    "    return unique_terms\n",
    "\n",
    "# Apply the function to remove duplicates from 'cond_desc' column\n",
    "condition_aggregated['hcc_model_type'] = condition_aggregated['hcc_model_type'].apply(remove_duplicates)\n",
    "merged_data = pd.merge(merged_data, condition_aggregated, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71bf2433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 241 entries, consec_tenure_month to hcc_model_type\n",
      "dtypes: float64(224), int64(17)\n",
      "memory usage: 2.7 GB\n"
     ]
    }
   ],
   "source": [
    "merged_data['hcc_model_type'] = merged_data['hcc_model_type'].fillna(0)\n",
    "\n",
    "# Step 2: Replace specific strings with numeric values\n",
    "merged_data['hcc_model_type'] = merged_data['hcc_model_type'].replace({'U': 0, 'MEDICAL': 1, 'ESRD': 2})\n",
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f1bd8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims_data = claims_data.drop(columns = ['dos_year','clm_unique_key','serv_date_skey'])\n",
    "#claims_data = claims_data.groupby('id').apply(lambda group: group.notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b958e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace 'Y' with 1 and everything else (including NaN) with 0\n",
    "claims_data_numeric = claims_data.replace({'Y': 1}).fillna(0)\n",
    "\n",
    "# Step 2: Group by 'id' and sum the numeric values to count the number of 'Y's in each column\n",
    "claims_data_group = claims_data_numeric.groupby('id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1c9e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_data_group=claims_data_group.drop(columns = ['dos_year','clm_unique_key','serv_date_skey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3011ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1329101 entries, 0 to 1329100\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   id                        1329101 non-null  int64  \n",
      " 1   pcp_visit                 1329101 non-null  float64\n",
      " 2   annual_wellness           1329101 non-null  float64\n",
      " 3   humana_paf                1329101 non-null  float64\n",
      " 4   preventative_visit        1329101 non-null  float64\n",
      " 5   comp_physical_exam        1329101 non-null  float64\n",
      " 6   ihwa                      1329101 non-null  float64\n",
      " 7   fqhc_visit                1329101 non-null  float64\n",
      " 8   telehealth                1329101 non-null  float64\n",
      " 9   endocrinologist_visit     1329101 non-null  float64\n",
      " 10  oncolologist_visit        1329101 non-null  float64\n",
      " 11  radiologist_visit         1329101 non-null  float64\n",
      " 12  podiatrist_visit          1329101 non-null  float64\n",
      " 13  ophthalmologist_visit     1329101 non-null  float64\n",
      " 14  optometrist_visit         1329101 non-null  float64\n",
      " 15  physical_therapist_visit  1329101 non-null  float64\n",
      " 16  cardiologist_visit        1329101 non-null  float64\n",
      " 17  gastroenterologist_visit  1329101 non-null  float64\n",
      " 18  orthopedist_visit         1329101 non-null  float64\n",
      " 19  obgyn_visit               1329101 non-null  float64\n",
      " 20  nephroloogist_visit       1329101 non-null  float64\n",
      " 21  pulmonologist_visit       1329101 non-null  float64\n",
      " 22  urgent_care_visit         1329101 non-null  float64\n",
      " 23  er_visit                  1329101 non-null  float64\n",
      "dtypes: float64(23), int64(1)\n",
      "memory usage: 243.4 MB\n"
     ]
    }
   ],
   "source": [
    "claims_data_group.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff3a91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, claims_data_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea5f0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1527904 entries, 0 to 1527903\n",
      "Columns: 264 entries, consec_tenure_month to er_visit\n",
      "dtypes: float64(247), int64(17)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75291cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jade/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:06:38] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6943854493571263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.81      0.74    168453\n",
      "           1       0.70      0.56      0.62    137128\n",
      "\n",
      "    accuracy                           0.69    305581\n",
      "   macro avg       0.70      0.68      0.68    305581\n",
      "weighted avg       0.70      0.69      0.69    305581\n",
      "\n",
      "XGBoost AUC: 0.7591357501006044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Assuming merged_data is already available\n",
    "\n",
    "# Step 1: Prepare the data\n",
    "# Replace 'target_column' with the actual name of your target column\n",
    "X = merged_data.drop(columns=['preventive_visit_gap_ind'])  # Features\n",
    "y = merged_data['preventive_visit_gap_ind']  # Target\n",
    "\n",
    "# Step 1.1: Impute missing values (NaN) with 0\n",
    "X = X.fillna(0)\n",
    "y = y.fillna(0)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train and evaluate models\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"XGBoost Accuracy:\", xgb_acc)\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming y_test is the true labels and y_pred_xgb are the predicted labels\n",
    "y_pred_xgb_proba = xgb_model.predict_proba(X_test)[:, 1]  # Get the predicted probabilities for the positive class\n",
    "\n",
    "# Calculate AUC\n",
    "xgb_auc = roc_auc_score(y_test, y_pred_xgb_proba)\n",
    "print(\"XGBoost AUC:\", xgb_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e21f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_data = quality_data.drop(columns = ['measurement_year','measure_name','measure_desc','base_event_date','eligible_cnt'])\n",
    "quality_data['measure_type'] = quality_data['measure_type'].fillna(10008)\n",
    "quality_data['measure_type'] = quality_data['measure_type'].replace({'Patient Safety': 1, 'Patient Experience': 0, 'HEDIS':2})\n",
    "#quality_data = quality_data.groupby('id').apply(lambda group: group.notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2ac01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_data_group=quality_data.groupby('id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eaf30e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure_type</th>\n",
       "      <th>compliant_cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>30.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>0</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>20</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>23</td>\n",
       "      <td>38.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>22</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000000</th>\n",
       "      <td>8</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         measure_type  compliant_cnt\n",
       "id                                  \n",
       "1                   9          30.32\n",
       "2                   6           6.00\n",
       "3                  36          39.00\n",
       "4                  24          14.00\n",
       "6                   2           1.00\n",
       "...               ...            ...\n",
       "1999995             0          24.00\n",
       "1999996            20           6.00\n",
       "1999997            23          38.64\n",
       "1999998            22          10.00\n",
       "2000000             8           2.00\n",
       "\n",
       "[1350479 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcc4432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, quality_data_group, on='id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "254971f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consec_tenure_month</th>\n",
       "      <th>all_mm_tenure</th>\n",
       "      <th>tenure_band</th>\n",
       "      <th>dual_eligible_ind</th>\n",
       "      <th>disabled_ind</th>\n",
       "      <th>lis_ind</th>\n",
       "      <th>id</th>\n",
       "      <th>rx_overall_pmpm_cost</th>\n",
       "      <th>rx_overall_net_paid_pmpm_cost</th>\n",
       "      <th>rx_overall_coins_pmpm_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>cardiologist_visit</th>\n",
       "      <th>gastroenterologist_visit</th>\n",
       "      <th>orthopedist_visit</th>\n",
       "      <th>obgyn_visit</th>\n",
       "      <th>nephroloogist_visit</th>\n",
       "      <th>pulmonologist_visit</th>\n",
       "      <th>urgent_care_visit</th>\n",
       "      <th>er_visit</th>\n",
       "      <th>measure_type</th>\n",
       "      <th>compliant_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1551235</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1643841</td>\n",
       "      <td>8.743333</td>\n",
       "      <td>1.269167</td>\n",
       "      <td>1.855833</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540296</td>\n",
       "      <td>510.660830</td>\n",
       "      <td>434.550840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>729600</td>\n",
       "      <td>319.575000</td>\n",
       "      <td>236.170840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>716836</td>\n",
       "      <td>71.818340</td>\n",
       "      <td>71.818340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527899</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1551651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527900</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1584607</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527901</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1246390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527902</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>695942</td>\n",
       "      <td>96.273330</td>\n",
       "      <td>63.232500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527903</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>209485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527904 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         consec_tenure_month  all_mm_tenure  tenure_band  dual_eligible_ind  \\\n",
       "0                          6              6         0.25                  0   \n",
       "1                         59             59         4.50                  0   \n",
       "2                        119            119         7.00                  0   \n",
       "3                         24             24         1.75                  0   \n",
       "4                         60             76         4.50                  0   \n",
       "...                      ...            ...          ...                ...   \n",
       "1527899                    4              4         0.25                  0   \n",
       "1527900                   23             23         1.75                  0   \n",
       "1527901                    3              3         0.25                  0   \n",
       "1527902                   24             24         1.75                  0   \n",
       "1527903                   12             12         0.75                  0   \n",
       "\n",
       "         disabled_ind  lis_ind       id  rx_overall_pmpm_cost  \\\n",
       "0                   0        0  1551235             25.000000   \n",
       "1                   1        0  1643841              8.743333   \n",
       "2                   0        0   540296            510.660830   \n",
       "3                   1        0   729600            319.575000   \n",
       "4                   0        0   716836             71.818340   \n",
       "...               ...      ...      ...                   ...   \n",
       "1527899             0        0  1551651              0.000000   \n",
       "1527900             0        0  1584607              0.595833   \n",
       "1527901             0        0  1246390                   NaN   \n",
       "1527902             1        0   695942             96.273330   \n",
       "1527903             0        0   209485                   NaN   \n",
       "\n",
       "         rx_overall_net_paid_pmpm_cost  rx_overall_coins_pmpm_cost  ...  \\\n",
       "0                            25.000000                    0.000000  ...   \n",
       "1                             1.269167                    1.855833  ...   \n",
       "2                           434.550840                    0.000000  ...   \n",
       "3                           236.170840                    0.000000  ...   \n",
       "4                            71.818340                    0.000000  ...   \n",
       "...                                ...                         ...  ...   \n",
       "1527899                       0.000000                    0.000000  ...   \n",
       "1527900                       0.000000                    0.000000  ...   \n",
       "1527901                            NaN                         NaN  ...   \n",
       "1527902                      63.232500                    0.000000  ...   \n",
       "1527903                            NaN                         NaN  ...   \n",
       "\n",
       "         cardiologist_visit  gastroenterologist_visit  orthopedist_visit  \\\n",
       "0                       0.0                       0.0                0.0   \n",
       "1                       5.0                       0.0                0.0   \n",
       "2                       5.0                       0.0                0.0   \n",
       "3                       6.0                       8.0                0.0   \n",
       "4                       0.0                       0.0                0.0   \n",
       "...                     ...                       ...                ...   \n",
       "1527899                 NaN                       NaN                NaN   \n",
       "1527900                 0.0                       0.0                0.0   \n",
       "1527901                 0.0                       0.0                0.0   \n",
       "1527902                12.0                       2.0                0.0   \n",
       "1527903                 NaN                       NaN                NaN   \n",
       "\n",
       "         obgyn_visit  nephroloogist_visit  pulmonologist_visit  \\\n",
       "0                0.0                  0.0                  0.0   \n",
       "1                0.0                  0.0                  0.0   \n",
       "2                0.0                  0.0                  0.0   \n",
       "3                0.0                  2.0                 25.0   \n",
       "4                0.0                  0.0                  0.0   \n",
       "...              ...                  ...                  ...   \n",
       "1527899          NaN                  NaN                  NaN   \n",
       "1527900          0.0                  0.0                  0.0   \n",
       "1527901          0.0                  0.0                  0.0   \n",
       "1527902          0.0                  6.0                  0.0   \n",
       "1527903          NaN                  NaN                  NaN   \n",
       "\n",
       "         urgent_care_visit  er_visit  measure_type  compliant_cnt  \n",
       "0                      0.0       0.0           NaN            NaN  \n",
       "1                      0.0       7.0          66.0           29.0  \n",
       "2                      0.0       1.0          18.0           10.0  \n",
       "3                      0.0       9.0          22.0           28.0  \n",
       "4                      0.0       2.0          45.0           18.0  \n",
       "...                    ...       ...           ...            ...  \n",
       "1527899                NaN       NaN           NaN            NaN  \n",
       "1527900                0.0       0.0           NaN            NaN  \n",
       "1527901                0.0       0.0           NaN            NaN  \n",
       "1527902                1.0       0.0           NaN            NaN  \n",
       "1527903                NaN       NaN           NaN            NaN  \n",
       "\n",
       "[1527904 rows x 266 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "104a0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jade/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [00:10:57] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id     score  rank\n",
      "1403537   399622  0.998955     1\n",
      "1082446   645020  0.998916     2\n",
      "886590   1537515  0.998860     3\n",
      "1080831   719985  0.998694     4\n",
      "1489309   101191  0.998665     5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Assuming X_train and y_train are your training data, and X_test includes 'id' for patients\n",
    "# X_test['id'] should have patient IDs, and X_test is your test data excluding the target variable\n",
    "\n",
    "# Step 1: Train the XGBoost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Predict the probabilities for the positive class (participation in preventive care)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1 (participation)\n",
    "\n",
    "# Step 3: Create a DataFrame with 'id' and 'score' (probability of participating in preventive care)\n",
    "submission = pd.DataFrame({\n",
    "    'id': X_test['id'],    # This is the patient ID column\n",
    "    'score': y_pred_proba  # This is the predicted probability of participation (class 1)\n",
    "})\n",
    "\n",
    "# Step 4: Rank the patients based on the predicted score\n",
    "submission['rank'] = submission['score'].rank(ascending=False, method='first').astype(int)\n",
    "\n",
    "# Step 5: Sort by rank (optional)\n",
    "submission = submission.sort_values(by='rank')\n",
    "\n",
    "# Step 6: Save the submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Display the top of the submission DataFrame\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff5b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jade/Desktop/Humana/Training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c6c0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
